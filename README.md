# Agent Foundry

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.12%20%7C%203.13-blue)

> **Version 0.1.0**
> Multiâ€‘agent framework for planning, executing, and evaluating complex tasks with a focus on reproducibility and developer ergonomics.

---

## âœ¨ Key Features

- **Composable Actors** â€“Â Planner, Builder, Executor, Manager and more, each isolated in `src/actors/`
- **Promptâ€‘centric Design** â€“Â Actor prompts live in `src/actors/prompts/` and can be edited without touching Python code
- **Typed Domain Models** â€“Â Powered by _PydanticÂ v2_ for safe data interchange (`src/core/models.py`)
- **Environmentâ€‘firstÂ config** â€“Â All runtime knobs live in `src/core/config.py` and load from `.env`
- **`uv` Native** â€“Â Dependency resolution & virtualâ€‘env management driven by the lightningâ€‘fast [**uv**](https://github.com/astral-sh/uv) tool
- **MakefileÂ Tasks** â€“Â Common workflows like _sync_, _format_, _lint_, _tests_, _coverage_ baked in
- **100% Test Coverage Target** â€“Â CI fails if unit coverage <Â 95â€¯%

---

## ğŸ—‚ï¸ Project Layout

```bash
.
â”œâ”€â”€ env-sample.txt
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â”œâ”€â”€ notes/
â”‚   â””â”€â”€ openai-models.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ samples/
â”‚   â”œâ”€â”€ files.json
â”‚   â”œâ”€â”€ mortgage/
â”‚   â”‚   â”œâ”€â”€ _task.yaml
â”‚   â”‚   â”œâ”€â”€ credit_report.pdf
â”‚   â”‚   â”œâ”€â”€ loe_sample.png
â”‚   â”‚   â””â”€â”€ ps_sample.png
â”‚   â””â”€â”€ research/
â”‚       â”œâ”€â”€ _task.yaml
â”‚       â”œâ”€â”€ first_then.pdf
â”‚       â”œâ”€â”€ org_chart.png
â”‚       â””â”€â”€ us_symbols.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ actors/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ builder.py
â”‚   â”‚   â”œâ”€â”€ executors.py
â”‚   â”‚   â”œâ”€â”€ manager.py
â”‚   â”‚   â”œâ”€â”€ planner.py
â”‚   â”‚   â””â”€â”€ prompts/
â”‚   â”‚       â”œâ”€â”€ planner.md
â”‚   â”‚       â”œâ”€â”€ re_planner.md
â”‚   â”‚       â””â”€â”€ tasks.md
â”‚   â”œâ”€â”€ cmd.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ config.yaml.j2
â”‚   â”‚   â”œâ”€â”€ constants.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ processor.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ mcps.py
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ web_search.py
â”‚   â””â”€â”€ version.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ __init__.py
â””â”€â”€ uv.lock
```

> **Note**: `__pycache__/` and `__MACOSX/` artefacts are ignored â€“Â they need not be committed.

---

## ğŸš€ QuickÂ Start

## ğŸƒ Usage Example

The system is driven by a **goal** and a list of **context artifacts**. At runtime these are published to the [_mcpâ€‘blackboard_](https://github.com/peekwez/mcp-blackboard/tree/main) server, which every actor can query for memory & context. Set the server URL via env var **`MCP_BLACKBOARD_SERVER`** (defaults to `http://localhost:8000/sse`).

### Example goal

> Create a oneâ€‘page executive brief on the economic impact of Canadaâ€™s 2024â€‘2025 carbon tax changes. Cite at least three sources.

### Example context list

```text
file:///mnt/shared/data/research/us_symbols.csv
file:///mnt/shared/data/research/org_chart.png
file:///mnt/shared/data/research/first_then.pdf
http://goldfinger.utias.utoronto.ca/dwz/
https://www.youtube.com/watch?v=yYALsys-P_w
```

### Run

```bash
# assume BLACKBOARD_URL already exported
make run GOAL="Create a one-page executive brief on the economic impact of Canadaâ€™s 2024-2025 carbon tax changes. Cite at least three sources." \             CONTEXT="abfs://mcp-tests/generic/us_symbols.csv,abfs://mcp-tests/generic/org_chart.png,abfs://mcp-tests/generic/first_then.pdf,http://goldfinger.utias.utoronto.ca/dwz/,https://www.youtube.com/watch?v=yYALsys-P_w"
```

The CLI flags `GOAL` and `CONTEXT` are read by `main.py`, which publishes them to the blackboard and starts the actor workflow.

### 1. Install **uv**

```bash
# Unix & macOS
curl -Ls https://astral.sh/uv/install.sh | sh

# Windows (PowerShell)
irm https://astral.sh/uv/install.ps1 | iex
```

### 2. Sync the environment

```bash
# Creates a .venv, resolves lockfile, installs runtime + dev deps
make sync          # equivalent to: uv sync --all-extras --all-packages --group dev
```

### 3. Run the application

```bash
make run           # â‡’ cd src && uv run -m main
```

`main.py` will:

1. Load configuration (`core.utils`)
2. Instantiate actors
3. Generate a plan from human input
4. Execute tasks and stream progress
5. Persist results

### 4. Developer Workflow

| Task         | Command         | Description                              |
| ------------ | --------------- | ---------------------------------------- |
| Format code  | `make format`   | Run **ruff** autoâ€‘formatter and fix lint |
| Static check | `make lint`     | Lint with ruff                           |
| Type check   | `make mypy`     | Mypy strict optional                     |
| Run tests    | `make tests`    | Execute **pytest** suite                 |
| Coverage     | `make coverage` | Fail if coverage <Â 95â€¯%                  |

> All tasks use `uv run` under the hood so they run inside the same virtualÂ env.

---

## ğŸ”Œ Configuration

All settings are environmentâ€‘driven. Create a `.env` in project root (see `core/models.py` for fields). Example:

```dotenv
# tavily and logfire
TAVILY_API_KEY=
LOGFIRE_WRITE_KEY=

# mcp blackboard server
MCP_BLACKBOARD_SERVER=http://localhost:8000/sse

# provider
MODEL_API_KEY=
MODEL_BASE_URL=https://genai-sharedservice-americas.pwc.com

# context builder agent
CONTEXT_BUILDER_MODEL=openai.o3-2025-04-16
CONTEXT_BUILDER_TEMPERATURE=0
CONTEXT_BUILDER_MAX_TOKENS=4096

# planner agent
PLANNER_MODEL=openai.o3-2025-04-16
PLANNER_TEMPERATURE=0
PLANNER_MAX_TOKENS=4096

# researcher agent
RESEARCHER_MODEL=openai.o3-2025-04-16
RESEARCHER_TEMPERATURE=0
RESEARCHER_MAX_TOKENS=8192

# extractor agent
EXTRACTOR_MODEL=openai.o3-mini-2025-01-31
EXTRACTOR_TEMPERATURE=0
EXTRACTOR_MAX_TOKENS=4096

# analyzer agent
ANALYZER_MODEL=openai.o3-mini-2025-01-31
ANALYZER_TEMPERATURE=0
ANALYZER_MAX_TOKENS=4096

# writer agent
WRITER_MODEL=openai.o1-2024-12-17
WRITER_TEMPERATURE=0.2
WRITER_MAX_TOKENS=16384

# editor agent
EDITOR_MODEL=openai.o1-2024-12-17
EDITOR_TEMPERATURE=0.2
EDITOR_MAX_TOKENS=16384

# evaluator agent
EVALUATOR_MODEL=openai.o3-mini-2025-01-31
EVALUATOR_TEMPERATURE=0
EVALUATOR_MAX_TOKENS=1024
```

---

## ğŸ§© Extending Agent Foundry

1. **New actor**

   ```bash
   touch src/actors/my_actor.py
   ```

   Inherit from `BaseActor` and register it in `actors/__init__.py`.

2. **Custom prompts**
   Drop a Markdown file in `actors/prompts/` and reference it via the actorâ€™s `prompt_file` attribute.

3. **Integrate external tools / MCPs**
   Extend `mcps.py` with a `{YourTool}MCP` class exposing the desired ops, then inject it where needed.

---

## ğŸ› ï¸ Dependencies

Runtime:

```toml
[
  "openai-agents>=0.0.12",
  "pydantic>=2.11.3",
  "python-dotenv>=1.1.0",
  "pyyaml>=6.0.2"
]
```

Devâ€‘only (installed by default via `make sync`):

```toml
[
  "coverage>=7.8.0",
  "ipython>=9.1.0",
  "mypy>=1.15.0",
  "pytest>=8.3.5",
  "pytest-cov>=6.1.1",
  "pytest-mock>=3.14.0",
  "rich>=14.0.0",
  "ruff>=0.11.7"
]
```

> All dependencies are locked in `uv.lock` for deterministic builds.

---

## ğŸ“œ License

Distributed under the MIT License. See [`LICENSE`](LICENSE) for more information.

---

## ğŸ™ Acknowledgements

- [Astralâ€‘SH uv](https://github.com/astral-sh/uv) for lightningâ€‘fast dependency management
- [OpenAIÂ AgentsÂ SDK](https://github.com/openai/openai-python/tree/main/openai/agents) for the agent runtime
